{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from time import time\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "class Opt(object):\n",
    "    dim = 10\n",
    "    n_epochs = 200\n",
    "    batch_size = dim*dim\n",
    "    lr = 0.00005\n",
    "    n_cpu = 1\n",
    "    latent_dim = 100\n",
    "    img_size = 28\n",
    "    channels = 1\n",
    "    n_critic = 5\n",
    "    sample_interval = 400\n",
    "opt = Opt()  \n",
    "\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            *block(1024, 2048),  # Extra layer\n",
    "            nn.Linear(2048, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        def block(in_feat, out_feat):\n",
    "            layers = [\n",
    "                nn.Linear(in_feat, out_feat),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ]\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.img_size ** 2, 512),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "\n",
    "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST( # Change to FashionMNIST\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "generator_optimizer = torch.optim.RMSprop(generator.parameters(), lr=opt.lr)\n",
    "discriminator_optimizer = torch.optim.RMSprop(discriminator.parameters(), lr=opt.lr)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "batches_done = 0\n",
    "saved_imgs = []\n",
    "for epoch in range(opt.n_epochs):\n",
    "    print('Epoch ' + str(epoch) + ' training ' , end=' ')\n",
    "    start = time()\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "        fake_imgs = generator(z).detach()\n",
    "        discriminator_loss = torch.mean(discriminator(fake_imgs)) - torch.mean(discriminator(real_imgs))\n",
    "\n",
    "        # Gradient Penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        # Update discriminator loss with gradient penalty\n",
    "        discriminator_loss += 10 * gradient_penalty\n",
    "\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        if i % opt.n_critic == 0:\n",
    "            generator_optimizer.zero_grad()\n",
    "            critics_fake_imgs = generator(z)\n",
    "            generator_loss = -torch.mean(discriminator(critics_fake_imgs))\n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "        batches_done += 1\n",
    "    end = time()\n",
    "    elapsed = end - start\n",
    "    print('done, took %.1f seconds.' % elapsed)\n",
    "    grid = torchvision.utils.make_grid(critics_fake_imgs.data.cpu(), nrow=opt.dim)\n",
    "    img = (np.transpose(grid.detach().numpy(), (1, 2 ,0)) * 255).astype(np.uint8)\n",
    "    saved_imgs.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_indexes = [0,50, 100, 150, 199]\n",
    "for i in img_indexes:\n",
    "    plt.figure(figsize = (opt.dim, opt.dim))\n",
    "    plt.imshow(saved_imgs[i], interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
